{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d717be0c",
   "metadata": {},
   "source": [
    "# Route Planning with Constraint-Based Clustering\n",
    "\n",
    "This notebook demonstrates the route planning feasibility workflow using **constraint-based clustering** from `geocluster.py` with **business rule constraints**.\n",
    "\n",
    "## Business Rules\n",
    "\n",
    "**Rule 1: Maximum Cluster Radius = 60 km**\n",
    "- Based on daily route coverage capability\n",
    "- Ensures feasibility within 8-hour work day\n",
    "- Prevents mega-clusters spanning multiple cities\n",
    "\n",
    "**Rule 2: Work Day Constraint = 8 hours max**\n",
    "- With P=50% field work: 4 hours for visits + travel\n",
    "- At ~50 km/h average: max ~200 km daily driving\n",
    "- 60 km radius cluster allows multiple visits within this budget\n",
    "\n",
    "## Key Differences from DBSCAN Approach\n",
    "\n",
    "- **DBSCAN**: Density-based, automatically finds clusters (data-driven)\n",
    "- **Center-Radius**: Guarantees max distance from center ‚â§ D (business rule: 60 km)\n",
    "- **Diameter**: Guarantees max pairwise distance ‚â§ D (stricter, business rule: 60 km)\n",
    "\n",
    "## Scenario\n",
    "Two synthetic sales representative territories:\n",
    "- **REP_001**: Stores generated within 50 km radius of Madrid\n",
    "- **REP_002**: Stores split between Guadalajara (25 km radius) and Cuenca (25 km radius), ~150 km apart\n",
    "\n",
    "**Note:** With D=60 km hard constraint, even REP_001 may produce multiple clusters if the maximum diameter exceeds constraints. Method selection (basic vs cluster-aware) is **data-driven** based on fragmentation score, not assumptions.\n",
    "\n",
    "We'll test **both constraint-based methods** with D=60 km and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e14e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully!\n",
      "‚úì geocluster module loaded\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('../src')  # Add src directory to path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import geocluster module\n",
    "from geocluster import (\n",
    "    cluster_by_center_radius,\n",
    "    cluster_by_diameter,\n",
    "    validate_center_radius_constraint,\n",
    "    validate_diameter_constraint,\n",
    "    compute_cluster_statistics,\n",
    "    haversine_distance\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")\n",
    "print(f\"‚úì geocluster module loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9f3b5",
   "metadata": {},
   "source": [
    "## 1. Helper Functions\n",
    "\n",
    "Reuse distance and matrix functions (geocluster has its own haversine, but we'll use consistent helper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2333de8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Madrid to Barcelona = 505.4 km (expected ~505 km)\n"
     ]
    }
   ],
   "source": [
    "def build_distance_matrix(coords):\n",
    "    \"\"\"\n",
    "    Build pairwise distance matrix using Haversine formula.\n",
    "    \"\"\"\n",
    "    n = len(coords)\n",
    "    dist_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dist = haversine_distance(\n",
    "                coords[i, 0], coords[i, 1],\n",
    "                coords[j, 0], coords[j, 1]\n",
    "            )\n",
    "            dist_matrix[i, j] = dist\n",
    "            dist_matrix[j, i] = dist\n",
    "    \n",
    "    return dist_matrix\n",
    "\n",
    "# Test\n",
    "test_dist = haversine_distance(40.4168, -3.7038, 41.3851, 2.1734)\n",
    "print(f\"Test: Madrid to Barcelona = {test_dist:.1f} km (expected ~505 km)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3390a0",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Store Data\n",
    "\n",
    "Same data generation as DBSCAN notebook for fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49585e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated store data:\n",
      "  REP_001 (Madrid): 31 stores\n",
      "  REP_002 (Guadalajara + Cuenca): 32 stores\n",
      "Total stores: 63\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Central Spain coordinates\n",
    "MADRID_CENTER = [40.4168, -3.7038]\n",
    "GUADALAJARA_CENTER = [40.6318, -3.1669]\n",
    "CUENCA_CENTER = [40.0703, -2.1374]\n",
    "\n",
    "def generate_stores_in_circle(center, radius_km, n_stores, store_prefix):\n",
    "    \"\"\"Generate stores uniformly distributed within a circle.\"\"\"\n",
    "    stores = []\n",
    "    lat_per_km = 1.0 / 111.0\n",
    "    lon_per_km = 1.0 / (111.0 * np.cos(np.radians(center[0])))\n",
    "    \n",
    "    for i in range(n_stores):\n",
    "        angle = np.random.uniform(0, 2 * np.pi)\n",
    "        r = radius_km * np.sqrt(np.random.uniform(0, 1))\n",
    "        dlat = r * np.cos(angle) * lat_per_km\n",
    "        dlon = r * np.sin(angle) * lon_per_km\n",
    "        \n",
    "        stores.append({\n",
    "            'store_id': f'{store_prefix}{i+1:03d}',\n",
    "            'latitude': center[0] + dlat,\n",
    "            'longitude': center[1] + dlon\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(stores)\n",
    "\n",
    "# Generate REP_001: Compact (Madrid)\n",
    "n_stores_compact = np.random.randint(25, 36)\n",
    "rep001_stores = generate_stores_in_circle(MADRID_CENTER, 50, n_stores_compact, 'MAD')\n",
    "rep001_stores['rep_id'] = 'REP_001'\n",
    "\n",
    "# Generate REP_002: Fragmented (Guadalajara + Cuenca)\n",
    "n_stores_fragmented = np.random.randint(25, 36)\n",
    "n_guadalajara = n_stores_fragmented // 2\n",
    "n_cuenca = n_stores_fragmented - n_guadalajara\n",
    "\n",
    "rep002_guadalajara = generate_stores_in_circle(GUADALAJARA_CENTER, 25, n_guadalajara, 'GUA')\n",
    "rep002_cuenca = generate_stores_in_circle(CUENCA_CENTER, 25, n_cuenca, 'CUE')\n",
    "rep002_stores = pd.concat([rep002_guadalajara, rep002_cuenca], ignore_index=True)\n",
    "rep002_stores['rep_id'] = 'REP_002'\n",
    "\n",
    "all_stores = pd.concat([rep001_stores, rep002_stores], ignore_index=True)\n",
    "\n",
    "print(f\"Generated store data:\")\n",
    "print(f\"  REP_001 (Madrid): {len(rep001_stores)} stores\")\n",
    "print(f\"  REP_002 (Guadalajara + Cuenca): {len(rep002_stores)} stores\")\n",
    "print(f\"Total stores: {len(all_stores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623945b",
   "metadata": {},
   "source": [
    "## 3. Assign Visit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c971a08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Visit data assigned\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(43)\n",
    "\n",
    "def assign_visit_data(stores_df):\n",
    "    \"\"\"Assign realistic visit frequencies and times.\"\"\"\n",
    "    n = len(stores_df)\n",
    "    visit_freq = []\n",
    "    for _ in range(n):\n",
    "        rand = np.random.random()\n",
    "        if rand < 0.60:\n",
    "            visit_freq.append(12)\n",
    "        elif rand < 0.90:\n",
    "            visit_freq.append(4)\n",
    "        else:\n",
    "            visit_freq.append(1)\n",
    "    \n",
    "    visit_times = np.random.uniform(45, 90, size=n)\n",
    "    stores_df['visit_frequency'] = visit_freq\n",
    "    stores_df['time_visit'] = visit_times.round(0).astype(int)\n",
    "    return stores_df\n",
    "\n",
    "all_stores = assign_visit_data(all_stores)\n",
    "print(\"‚úì Visit data assigned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d80528",
   "metadata": {},
   "source": [
    "## 4. Calculate Empirical Speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67b8d66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EMPIRICAL SPEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "REP_001 - 31 stores\n",
      "  Empirical Speed: 53.6 km/h\n",
      "\n",
      "REP_002 - 32 stores\n",
      "  Empirical Speed: 70.8 km/h\n"
     ]
    }
   ],
   "source": [
    "# Policy parameters\n",
    "WORKING_DAYS_PER_YEAR = 225\n",
    "HOURS_PER_DAY = 8\n",
    "MINUTES_PER_HOUR = 60\n",
    "P_FIELD_WORK = 0.50\n",
    "ROAD_FACTOR = 1.4\n",
    "\n",
    "def calculate_empirical_speed(stores_df, rep_id, P=P_FIELD_WORK):\n",
    "    \"\"\"Calculate empirical average speed for a representative.\"\"\"\n",
    "    rep_stores = stores_df[stores_df['rep_id'] == rep_id].copy()\n",
    "    coords = rep_stores[['latitude', 'longitude']].values\n",
    "    \n",
    "    total_available_time = WORKING_DAYS_PER_YEAR * HOURS_PER_DAY * MINUTES_PER_HOUR * P\n",
    "    total_visit_time = (rep_stores['visit_frequency'] * rep_stores['time_visit']).sum()\n",
    "    total_travel_time = total_available_time - total_visit_time\n",
    "    \n",
    "    avg_daily_visits = rep_stores['visit_frequency'].sum() / WORKING_DAYS_PER_YEAR\n",
    "    avg_trips_per_day = avg_daily_visits + 1\n",
    "    total_trips = avg_trips_per_day * WORKING_DAYS_PER_YEAR\n",
    "    \n",
    "    dist_matrix_haversine = build_distance_matrix(coords)\n",
    "    avg_distance_haversine = dist_matrix_haversine[np.triu_indices_from(dist_matrix_haversine, k=1)].mean()\n",
    "    \n",
    "    total_distance_haversine = total_trips * avg_distance_haversine\n",
    "    total_distance_road = total_distance_haversine * ROAD_FACTOR\n",
    "    \n",
    "    empirical_speed_km_per_min = total_distance_road / total_travel_time\n",
    "    empirical_speed_km_per_h = empirical_speed_km_per_min * 60\n",
    "    \n",
    "    return {\n",
    "        'rep_id': rep_id,\n",
    "        'n_stores': len(rep_stores),\n",
    "        'total_travel_time_min': total_travel_time,\n",
    "        'total_trips_per_year': total_trips,\n",
    "        'total_distance_road_km': total_distance_road,\n",
    "        'empirical_speed_km_per_min': empirical_speed_km_per_min,\n",
    "        'empirical_speed_km_per_h': empirical_speed_km_per_h,\n",
    "        'distance_matrix_haversine': dist_matrix_haversine,\n",
    "        'stores': rep_stores\n",
    "    }\n",
    "\n",
    "rep001_metrics = calculate_empirical_speed(all_stores, 'REP_001')\n",
    "rep002_metrics = calculate_empirical_speed(all_stores, 'REP_002')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EMPIRICAL SPEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "for metrics in [rep001_metrics, rep002_metrics]:\n",
    "    print(f\"\\n{metrics['rep_id']} - {metrics['n_stores']} stores\")\n",
    "    print(f\"  Empirical Speed: {metrics['empirical_speed_km_per_h']:.1f} km/h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18817e1a",
   "metadata": {},
   "source": [
    "## 5. Constraint-Based Clustering\n",
    "\n",
    "### Business Rules for Distance Constraint D\n",
    "\n",
    "**Rule 1: Maximum Cluster Radius = 60 km**\n",
    "- Ensures all stores within a cluster are reachable within reasonable daily driving\n",
    "- Prevents \"mega-clusters\" spanning multiple cities\n",
    "- Based on typical sales rep daily coverage capability\n",
    "\n",
    "**Rule 2: Respect 8-Hour Work Day Constraint**\n",
    "- With 50% field work time (P=0.5): 4 hours for visits + travel\n",
    "- At 50 km/h average speed: max ~200 km total daily driving\n",
    "\n",
    "- A 60 km radius cluster allows ~120 km round-trips within this budget- Protects against both over-clustering and under-clustering\n",
    "\n",
    "- Guarantees operational feasibility\n",
    "\n",
    "**Distance Constraint Selection**: D = 60 km (business rule)- This is domain-driven, not data-driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "837046d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONSTRAINT-BASED CLUSTERING\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "REP_001 (Madrid - Compact) - Center-Radius Method\n",
      "==================================================\n",
      "  Max distance: 94.1 km\n",
      "\n",
      "Clustering Method: center_radius\n",
      "  Constraint: Max radius from center ‚â§ 60.0 km\n",
      "\n",
      "Clustering Results:\n",
      "  Number of clusters: 2\n",
      "  Constraint validation: ‚úì PASS\n",
      "\n",
      "Cluster Statistics:\n",
      "  Mean cluster size: 15.5 stores\n",
      "  Max radius: 59.8 km\n",
      "  Max diameter: 94.1 km\n",
      "\n",
      "==================================================\n",
      "REP_001 (Madrid - Compact) - Diameter Method\n",
      "==================================================\n",
      "  Max distance: 94.1 km\n",
      "\n",
      "Clustering Method: diameter\n",
      "  Constraint: Max pairwise distance ‚â§ 60.0 km\n",
      "\n",
      "Clustering Results:\n",
      "  Number of clusters: 5\n",
      "  Constraint validation: ‚úì PASS\n",
      "\n",
      "Cluster Statistics:\n",
      "  Mean cluster size: 6.2 stores\n",
      "  Max radius: 33.5 km\n",
      "  Max diameter: 59.4 km\n",
      "\n",
      "==================================================\n",
      "REP_002 (Guadalajara + Cuenca - Fragmented) - Center-Radius\n",
      "==================================================\n",
      "  Max distance: 148.1 km\n",
      "\n",
      "Clustering Method: center_radius\n",
      "  Constraint: Max radius from center ‚â§ 60.0 km\n",
      "\n",
      "Clustering Results:\n",
      "  Number of clusters: 2\n",
      "  Constraint validation: ‚úì PASS\n",
      "\n",
      "Cluster Statistics:\n",
      "  Mean cluster size: 16.0 stores\n",
      "  Max radius: 37.6 km\n",
      "  Max diameter: 46.7 km\n",
      "\n",
      "==================================================\n",
      "REP_002 (Guadalajara + Cuenca - Fragmented) - Diameter\n",
      "==================================================\n",
      "  Max distance: 148.1 km\n",
      "\n",
      "Clustering Method: diameter\n",
      "  Constraint: Max pairwise distance ‚â§ 60.0 km\n",
      "\n",
      "Clustering Results:\n",
      "  Number of clusters: 2\n",
      "  Constraint validation: ‚úì PASS\n",
      "\n",
      "Cluster Statistics:\n",
      "  Mean cluster size: 16.0 stores\n",
      "  Max radius: 25.9 km\n",
      "  Max diameter: 46.7 km\n"
     ]
    }
   ],
   "source": [
    "def apply_constraint_clustering(stores_df, dist_matrix_km, method='center_radius', D_max=60.0):\n",
    "    \"\"\"\n",
    "    Apply constraint-based clustering with business rule constraints.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str\n",
    "        'center_radius' or 'diameter'\n",
    "    D_max : float\n",
    "        Maximum cluster radius in km (business rule: 60 km)\n",
    "    \"\"\"\n",
    "    coords = stores_df[['latitude', 'longitude']].values\n",
    "    \n",
    "    # Business Rule: D = 60 km (max cluster radius)\n",
    "    # This ensures:\n",
    "    # 1. Daily route feasibility (within 8-hour work day)\n",
    "    # 2. No mega-clusters spanning multiple cities\n",
    "    # 3. Reasonable travel times for sales reps\n",
    "    D = D_max\n",
    "    \n",
    "    # Show distance statistics for context\n",
    "    all_dists = dist_matrix_km[np.triu_indices_from(dist_matrix_km, k=1)]\n",
    "    max_dist = all_dists.max()\n",
    "    print(f\"  Max distance: {max_dist:.1f} km\")\n",
    "    print(f\"\\nClustering Method: {method}\")\n",
    "    print(f\"  Constraint: {'Max radius from center' if method == 'center_radius' else 'Max pairwise distance'} ‚â§ {D:.1f} km\")\n",
    "    \n",
    "    # Apply clustering\n",
    "    if method == 'center_radius':\n",
    "        labels, centers, n_clusters = cluster_by_center_radius(coords, D)\n",
    "        is_valid, violations = validate_center_radius_constraint(coords, labels, centers, D)\n",
    "    else:  # diameter\n",
    "        labels, centers, n_clusters = cluster_by_diameter(coords, D)\n",
    "        is_valid, violations = validate_diameter_constraint(coords, labels, D)\n",
    "    \n",
    "    print(f\"\\nClustering Results:\")\n",
    "    print(f\"  Number of clusters: {n_clusters}\")\n",
    "    print(f\"  Constraint validation: {'‚úì PASS' if is_valid else '‚úó FAIL'}\")\n",
    "    \n",
    "    if not is_valid:\n",
    "        print(f\"  Violations: {len(violations)}\")\n",
    "    \n",
    "    # Compute statistics\n",
    "    stats = compute_cluster_statistics(coords, labels, centers)\n",
    "    print(f\"\\nCluster Statistics:\")\n",
    "    print(f\"  Mean cluster size: {stats['mean_cluster_size']:.1f} stores\")\n",
    "    print(f\"  Max radius: {stats['max_radius_overall']:.1f} km\")\n",
    "    print(f\"  Max diameter: {stats['max_diameter_overall']:.1f} km\")\n",
    "    \n",
    "    return {\n",
    "        'labels': labels,\n",
    "        'centers': centers,\n",
    "        'n_clusters': n_clusters,\n",
    "        'D': D,\n",
    "        'method': method,\n",
    "        'is_valid': is_valid,\n",
    "        'stats': stats\n",
    "    }\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CONSTRAINT-BASED CLUSTERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REP_001 (Madrid - Compact) - Center-Radius Method\")\n",
    "print(\"=\"*50)\n",
    "rep001_clustering_cr = apply_constraint_clustering(\n",
    "    rep001_metrics['stores'],\n",
    "    rep001_metrics['distance_matrix_haversine'],\n",
    "    method='center_radius'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REP_001 (Madrid - Compact) - Diameter Method\")\n",
    "print(\"=\"*50)\n",
    "rep001_clustering_diam = apply_constraint_clustering(\n",
    "    rep001_metrics['stores'],\n",
    "    rep001_metrics['distance_matrix_haversine'],\n",
    "    method='diameter'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REP_002 (Guadalajara + Cuenca - Fragmented) - Center-Radius\")\n",
    "print(\"=\"*50)\n",
    "rep002_clustering_cr = apply_constraint_clustering(\n",
    "    rep002_metrics['stores'],\n",
    "    rep002_metrics['distance_matrix_haversine'],\n",
    "    method='center_radius'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REP_002 (Guadalajara + Cuenca - Fragmented) - Diameter\")\n",
    "print(\"=\"*50)\n",
    "rep002_clustering_diam = apply_constraint_clustering(\n",
    "    rep002_metrics['stores'],\n",
    "    rep002_metrics['distance_matrix_haversine'],\n",
    "    method='diameter'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b4b03",
   "metadata": {},
   "source": [
    "## 6. Compare Clustering Methods\n",
    "\n",
    "Visualize differences between center-radius and diameter approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a35238da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLUSTERING METHOD COMPARISON\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rep_id</th>\n",
       "      <th>method</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>max_radius_km</th>\n",
       "      <th>max_diameter_km</th>\n",
       "      <th>mean_cluster_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REP_001</td>\n",
       "      <td>Center-Radius</td>\n",
       "      <td>2</td>\n",
       "      <td>59.833108</td>\n",
       "      <td>94.054458</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REP_001</td>\n",
       "      <td>Diameter</td>\n",
       "      <td>5</td>\n",
       "      <td>33.500877</td>\n",
       "      <td>59.374684</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REP_002</td>\n",
       "      <td>Center-Radius</td>\n",
       "      <td>2</td>\n",
       "      <td>37.635967</td>\n",
       "      <td>46.743843</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REP_002</td>\n",
       "      <td>Diameter</td>\n",
       "      <td>2</td>\n",
       "      <td>25.943843</td>\n",
       "      <td>46.743843</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rep_id         method  n_clusters  max_radius_km  max_diameter_km  \\\n",
       "0  REP_001  Center-Radius           2      59.833108        94.054458   \n",
       "1  REP_001       Diameter           5      33.500877        59.374684   \n",
       "2  REP_002  Center-Radius           2      37.635967        46.743843   \n",
       "3  REP_002       Diameter           2      25.943843        46.743843   \n",
       "\n",
       "   mean_cluster_size  \n",
       "0               15.5  \n",
       "1                6.2  \n",
       "2               16.0  \n",
       "3               16.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Actual Results with D=60 km Business Rule:\n",
      "\n",
      "  REP_001 (Madrid, generated within 50 km radius):\n",
      "    ‚Ä¢ Actual n_clusters: 2 (Center-Radius)\n",
      "    ‚Ä¢ Max diameter: 94.1 km\n",
      "    ‚Ä¢ Explanation: Some stores exceed 60 km from optimal center\n",
      "    ‚Ä¢ Hard constraint forces split into multiple clusters\n",
      "\n",
      "  REP_002 (Guadalajara + Cuenca, 150 km apart):\n",
      "    ‚Ä¢ Actual n_clusters: 2 (Center-Radius)\n",
      "    ‚Ä¢ Max inter-cluster: 106.1 km\n",
      "    ‚Ä¢ Natural separation between cities respected by constraint\n",
      "\n",
      "üí° Key Insights:\n",
      "  ‚Ä¢ Diameter method produces MORE clusters (stricter pairwise constraint)\n",
      "  ‚Ä¢ Center-Radius enforces hard guarantees on cluster radius\n",
      "  ‚Ä¢ Business rule D=60 km ensures operational feasibility\n",
      "  ‚Ä¢ Even 'compact' territories may require multiple clusters\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CLUSTERING METHOD COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "for rep_id, cr_result, diam_result in [\n",
    "    ('REP_001', rep001_clustering_cr, rep001_clustering_diam),\n",
    "    ('REP_002', rep002_clustering_cr, rep002_clustering_diam)\n",
    "]:\n",
    "    comparison_data.append({\n",
    "        'rep_id': rep_id,\n",
    "        'method': 'Center-Radius',\n",
    "        'n_clusters': cr_result['n_clusters'],\n",
    "        'max_radius_km': cr_result['stats']['max_radius_overall'],\n",
    "        'max_diameter_km': cr_result['stats']['max_diameter_overall'],\n",
    "        'mean_cluster_size': cr_result['stats']['mean_cluster_size']\n",
    "    })\n",
    "    comparison_data.append({\n",
    "        'rep_id': rep_id,\n",
    "        'method': 'Diameter',\n",
    "        'n_clusters': diam_result['n_clusters'],\n",
    "        'max_radius_km': diam_result['stats']['max_radius_overall'],\n",
    "        'max_diameter_km': diam_result['stats']['max_diameter_overall'],\n",
    "        'mean_cluster_size': diam_result['stats']['mean_cluster_size']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\")\n",
    "display(comparison_df)\n",
    "\n",
    "print(\"\\nüìä Actual Results with D=60 km Business Rule:\")\n",
    "print(\"\\n  REP_001 (Madrid, generated within 50 km radius):\")\n",
    "print(f\"    ‚Ä¢ Actual n_clusters: {rep001_clustering_cr['n_clusters']} (Center-Radius)\")\n",
    "print(f\"    ‚Ä¢ Max diameter: {rep001_clustering_cr['stats']['max_diameter_overall']:.1f} km\")\n",
    "print(\"    ‚Ä¢ Explanation: Some stores exceed 60 km from optimal center\")\n",
    "print(\"    ‚Ä¢ Hard constraint forces split into multiple clusters\")\n",
    "print(\"\\n  REP_002 (Guadalajara + Cuenca, 150 km apart):\")\n",
    "print(f\"    ‚Ä¢ Actual n_clusters: {rep002_clustering_cr['n_clusters']} (Center-Radius)\")\n",
    "print(f\"    ‚Ä¢ Max inter-cluster: {rep002_frag['max_inter_dist_km']:.1f} km\")\n",
    "print(\"    ‚Ä¢ Natural separation between cities respected by constraint\")\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"  ‚Ä¢ Diameter method produces MORE clusters (stricter pairwise constraint)\")\n",
    "print(\"  ‚Ä¢ Center-Radius enforces hard guarantees on cluster radius\")\n",
    "print(\"  ‚Ä¢ Business rule D=60 km ensures operational feasibility\")\n",
    "print(\"  ‚Ä¢ Even 'compact' territories may require multiple clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe6462",
   "metadata": {},
   "source": [
    "## 7. Calculate Fragmentation Scores\n",
    "\n",
    "Use Center-Radius results for downstream analysis (more efficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "890d2d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FRAGMENTATION ANALYSIS (Center-Radius Method)\n",
      "================================================================================\n",
      "\n",
      "REP_001\n",
      "--------------------------------------------------\n",
      "Number of clusters: 2\n",
      "Mean intra-cluster distance: 42.0 km\n",
      "Max inter-cluster distance: 69.0 km\n",
      "\n",
      "üéØ Fragmentation Score (F_r): 0.106\n",
      "   ‚ö† Moderate fragmentation\n",
      "   ‚Üí CLUSTER-AWARE METHOD (recommended)\n",
      "\n",
      "REP_002\n",
      "--------------------------------------------------\n",
      "Number of clusters: 2\n",
      "Mean intra-cluster distance: 23.5 km\n",
      "Max inter-cluster distance: 106.1 km\n",
      "\n",
      "üéØ Fragmentation Score (F_r): 0.282\n",
      "   ‚ö† Moderate fragmentation\n",
      "   ‚Üí CLUSTER-AWARE METHOD (recommended)\n"
     ]
    }
   ],
   "source": [
    "def calculate_fragmentation_score(stores_df, labels, centers, dist_matrix_km):\n",
    "    \"\"\"Calculate fragmentation score F_r.\"\"\"\n",
    "    n_stores = len(stores_df)\n",
    "    n_clusters = len(set(labels))\n",
    "    \n",
    "    # Mean intra-cluster distance\n",
    "    intra_distances = []\n",
    "    for cluster_id in set(labels):\n",
    "        cluster_mask = labels == cluster_id\n",
    "        cluster_indices = np.where(cluster_mask)[0]\n",
    "        if len(cluster_indices) > 1:\n",
    "            cluster_dists = dist_matrix_km[np.ix_(cluster_indices, cluster_indices)]\n",
    "            cluster_dists = cluster_dists[np.triu_indices_from(cluster_dists, k=1)]\n",
    "            intra_distances.extend(cluster_dists)\n",
    "    \n",
    "    mean_intra_dist = np.mean(intra_distances) if intra_distances else 0\n",
    "    \n",
    "    # Max inter-cluster distance\n",
    "    if n_clusters > 1:\n",
    "        inter_dists = []\n",
    "        for i in range(len(centers)):\n",
    "            for j in range(i+1, len(centers)):\n",
    "                dist = haversine_distance(\n",
    "                    centers[i, 0], centers[i, 1],\n",
    "                    centers[j, 0], centers[j, 1]\n",
    "                )\n",
    "                inter_dists.append(dist)\n",
    "        max_inter_dist = max(inter_dists)\n",
    "    else:\n",
    "        max_inter_dist = 0\n",
    "    \n",
    "    # Fragmentation score\n",
    "    F_r = (n_clusters / n_stores) * (max_inter_dist / mean_intra_dist) if mean_intra_dist > 0 else 0\n",
    "    \n",
    "    if F_r < 0.1:\n",
    "        recommendation = \"BASIC METHOD (single speed)\"\n",
    "        status = \"‚úì Compact territory\"\n",
    "    elif F_r < 0.3:\n",
    "        recommendation = \"CLUSTER-AWARE METHOD (recommended)\"\n",
    "        status = \"‚ö† Moderate fragmentation\"\n",
    "    else:\n",
    "        recommendation = \"CLUSTER-AWARE METHOD (required)\"\n",
    "        status = \"‚ö†Ô∏è High fragmentation\"\n",
    "    \n",
    "    return {\n",
    "        'F_r': F_r,\n",
    "        'n_clusters': n_clusters,\n",
    "        'n_stores': n_stores,\n",
    "        'mean_intra_dist_km': mean_intra_dist,\n",
    "        'max_inter_dist_km': max_inter_dist,\n",
    "        'recommendation': recommendation,\n",
    "        'status': status\n",
    "    }\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FRAGMENTATION ANALYSIS (Center-Radius Method)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rep001_frag = calculate_fragmentation_score(\n",
    "    rep001_metrics['stores'],\n",
    "    rep001_clustering_cr['labels'],\n",
    "    rep001_clustering_cr['centers'],\n",
    "    rep001_metrics['distance_matrix_haversine']\n",
    ")\n",
    "\n",
    "rep002_frag = calculate_fragmentation_score(\n",
    "    rep002_metrics['stores'],\n",
    "    rep002_clustering_cr['labels'],\n",
    "    rep002_clustering_cr['centers'],\n",
    "    rep002_metrics['distance_matrix_haversine']\n",
    ")\n",
    "\n",
    "for rep_id, frag in [('REP_001', rep001_frag), ('REP_002', rep002_frag)]:\n",
    "    print(f\"\\n{rep_id}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Number of clusters: {frag['n_clusters']}\")\n",
    "    print(f\"Mean intra-cluster distance: {frag['mean_intra_dist_km']:.1f} km\")\n",
    "    print(f\"Max inter-cluster distance: {frag['max_inter_dist_km']:.1f} km\")\n",
    "    print(f\"\\nüéØ Fragmentation Score (F_r): {frag['F_r']:.3f}\")\n",
    "    print(f\"   {frag['status']}\")\n",
    "    print(f\"   ‚Üí {frag['recommendation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f27aef",
   "metadata": {},
   "source": [
    "## 8. Build Time-Distance Matrices\n",
    "\n",
    "**Data-Driven Method Selection:**\n",
    "- Decision based on **fragmentation score (F_r)**, not hardcoded assumptions\n",
    "- F_r < 0.1 ‚Üí Basic single-speed method (truly compact)\n",
    "- F_r ‚â• 0.1 ‚Üí Cluster-aware dual-speed method (multi-cluster)\n",
    "- Additional validation: speed differential must exceed 1.2√ó to justify dual speeds\n",
    "\n",
    "Uses Center-Radius clustering results for speed calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0af1d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TIME-DISTANCE MATRIX CONSTRUCTION (Data-Driven Method Selection)\n",
      "================================================================================\n",
      "\n",
      "REP_001 - F_r = 0.106\n",
      "--------------------------------------------------\n",
      "  Decision: CLUSTER-AWARE METHOD (F_r ‚â• 0.1, multi-cluster)\n",
      "  Intra-cluster: 47.3 km/h\n",
      "  Inter-cluster: 61.4 km/h\n",
      "  Speed differential: 1.30x\n",
      "  ‚úì Using cluster-aware method (sufficient speed differential)\n",
      "\n",
      "REP_002 - F_r = 0.282\n",
      "--------------------------------------------------\n",
      "  Decision: CLUSTER-AWARE METHOD (F_r ‚â• 0.1, multi-cluster)\n",
      "  Intra-cluster: 51.3 km/h\n",
      "  Inter-cluster: 77.0 km/h\n",
      "  Speed differential: 1.50x\n",
      "  ‚úì Using cluster-aware method (sufficient speed differential)\n",
      "\n",
      "================================================================================\n",
      "‚úì Time matrices constructed with data-driven method selection\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def build_basic_time_matrix(dist_matrix_km, speed_km_per_min, road_factor=ROAD_FACTOR):\n",
    "    \"\"\"Build time matrix using single speed.\"\"\"\n",
    "    dist_matrix_road = dist_matrix_km * road_factor\n",
    "    return dist_matrix_road / speed_km_per_min\n",
    "\n",
    "def calculate_cluster_speeds(stores_df, labels, dist_matrix_km, metrics, road_factor=ROAD_FACTOR):\n",
    "    \"\"\"Calculate intra/inter speeds using constrained optimization.\"\"\"\n",
    "    # Calculate intra-cluster distance\n",
    "    total_intra_distance = 0\n",
    "    for cluster_id in set(labels):\n",
    "        cluster_mask = labels == cluster_id\n",
    "        cluster_stores = stores_df[cluster_mask]\n",
    "        cluster_indices = np.where(cluster_mask)[0]\n",
    "        \n",
    "        if len(cluster_indices) > 1:\n",
    "            cluster_dists = dist_matrix_km[np.ix_(cluster_indices, cluster_indices)]\n",
    "            intra_avg = cluster_dists[np.triu_indices_from(cluster_dists, k=1)].mean()\n",
    "            cluster_visits = cluster_stores['visit_frequency'].sum()\n",
    "            intra_trips = cluster_visits - 1\n",
    "            total_intra_distance += intra_trips * intra_avg\n",
    "    \n",
    "    total_intra_distance_road = total_intra_distance * road_factor\n",
    "    total_distance_road = metrics['total_distance_road_km']\n",
    "    total_inter_distance_road = total_distance_road - total_intra_distance_road\n",
    "    total_travel_time = metrics['total_travel_time_min']\n",
    "    empirical_speed = metrics['empirical_speed_km_per_min']\n",
    "    \n",
    "    if total_inter_distance_road > 0:\n",
    "        # Try different speed ratios\n",
    "        best_alpha = None\n",
    "        best_speeds = None\n",
    "        \n",
    "        for alpha in [1.3, 1.5, 1.7, 2.0, 2.2]:\n",
    "            v_intra = (total_intra_distance_road + total_inter_distance_road / alpha) / total_travel_time\n",
    "            v_inter = alpha * v_intra\n",
    "            \n",
    "            if 0.6 <= v_intra <= 0.9 and 1.0 <= v_inter <= 1.4:\n",
    "                best_alpha = alpha\n",
    "                best_speeds = (v_intra, v_inter)\n",
    "                break\n",
    "        \n",
    "        if best_alpha is None:\n",
    "            alpha = 1.6\n",
    "            speed_intra = (total_intra_distance_road + total_inter_distance_road / alpha) / total_travel_time\n",
    "            speed_inter = alpha * speed_intra\n",
    "        else:\n",
    "            alpha = best_alpha\n",
    "            speed_intra, speed_inter = best_speeds\n",
    "        \n",
    "        intra_time = total_intra_distance_road / speed_intra\n",
    "        inter_time = total_inter_distance_road / speed_inter\n",
    "    else:\n",
    "        speed_intra = empirical_speed\n",
    "        speed_inter = empirical_speed\n",
    "        intra_time = total_travel_time\n",
    "        inter_time = 0\n",
    "        alpha = 1.0\n",
    "    \n",
    "    return speed_intra, speed_inter, {\n",
    "        'total_intra_distance_road_km': total_intra_distance_road,\n",
    "        'total_inter_distance_road_km': total_inter_distance_road,\n",
    "        'intra_travel_time_min': intra_time,\n",
    "        'inter_travel_time_min': inter_time,\n",
    "        'speed_intra_km_per_h': speed_intra * 60,\n",
    "        'speed_inter_km_per_h': speed_inter * 60,\n",
    "        'speed_ratio_alpha': alpha\n",
    "    }\n",
    "\n",
    "def build_cluster_aware_time_matrix(dist_matrix_km, labels, speed_intra, speed_inter, road_factor=ROAD_FACTOR):\n",
    "    \"\"\"Build time matrix with dual speeds.\"\"\"\n",
    "    n = len(dist_matrix_km)\n",
    "    time_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                dist_road = dist_matrix_km[i, j] * road_factor\n",
    "                if labels[i] == labels[j]:\n",
    "                    time_matrix[i, j] = dist_road / speed_intra\n",
    "                else:\n",
    "                    time_matrix[i, j] = dist_road / speed_inter\n",
    "    \n",
    "    return time_matrix\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TIME-DISTANCE MATRIX CONSTRUCTION (Data-Driven Method Selection)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Process both reps with data-driven method selection\n",
    "for rep_id, metrics, frag, clustering in [\n",
    "    ('REP_001', rep001_metrics, rep001_frag, rep001_clustering_cr),\n",
    "    ('REP_002', rep002_metrics, rep002_frag, rep002_clustering_cr)\n",
    "]:\n",
    "    print(f\"\\n{rep_id} - F_r = {frag['F_r']:.3f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Data-driven decision: use fragmentation score threshold\n",
    "    if frag['F_r'] < 0.1:\n",
    "        # Truly compact territory - use basic method\n",
    "        print(\"  Decision: BASIC METHOD (F_r < 0.1, truly compact)\")\n",
    "        time_matrix = build_basic_time_matrix(\n",
    "            metrics['distance_matrix_haversine'],\n",
    "            metrics['empirical_speed_km_per_min']\n",
    "        )\n",
    "        method_used = 'basic'\n",
    "        print(f\"  Speed: {metrics['empirical_speed_km_per_h']:.1f} km/h\")\n",
    "        print(f\"  Mean travel time: {time_matrix[np.triu_indices_from(time_matrix, k=1)].mean():.1f} min\")\n",
    "        \n",
    "    else:\n",
    "        # Multi-cluster territory - try cluster-aware method\n",
    "        print(\"  Decision: CLUSTER-AWARE METHOD (F_r ‚â• 0.1, multi-cluster)\")\n",
    "        speed_intra, speed_inter, cluster_details = calculate_cluster_speeds(\n",
    "            metrics['stores'],\n",
    "            clustering['labels'],\n",
    "            metrics['distance_matrix_haversine'],\n",
    "            metrics\n",
    "        )\n",
    "        \n",
    "        print(f\"  Intra-cluster: {cluster_details['speed_intra_km_per_h']:.1f} km/h\")\n",
    "        print(f\"  Inter-cluster: {cluster_details['speed_inter_km_per_h']:.1f} km/h\")\n",
    "        print(f\"  Speed differential: {speed_inter/speed_intra:.2f}x\")\n",
    "        \n",
    "        # Fallback if speed differential too low\n",
    "        if speed_inter / speed_intra < 1.2:\n",
    "            print(\"  ‚ö†Ô∏è  Falling back to basic method (speed differential < 1.2x)\")\n",
    "            time_matrix = build_basic_time_matrix(\n",
    "                metrics['distance_matrix_haversine'],\n",
    "                metrics['empirical_speed_km_per_min']\n",
    "            )\n",
    "            method_used = 'basic'\n",
    "        else:\n",
    "            print(\"  ‚úì Using cluster-aware method (sufficient speed differential)\")\n",
    "            time_matrix = build_cluster_aware_time_matrix(\n",
    "                metrics['distance_matrix_haversine'],\n",
    "                clustering['labels'],\n",
    "                speed_intra,\n",
    "                speed_inter\n",
    "            )\n",
    "            method_used = 'cluster_aware'\n",
    "    \n",
    "    # Store results\n",
    "    results[rep_id] = {\n",
    "        'method': method_used,\n",
    "        'clustering_method': 'center_radius',\n",
    "        'fragmentation_score': frag['F_r'],\n",
    "        'time_matrix': time_matrix\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì Time matrices constructed with data-driven method selection\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40cd539",
   "metadata": {},
   "source": [
    "## 9. Summary & Comparison\n",
    "\n",
    "### Key Findings: Business Rule-Based Clustering (D=60 km)\n",
    "\n",
    "**Actual Results with D=60 km:**\n",
    "- **REP_001 (Madrid, ~50 km radius)**: Produces **2 clusters** \n",
    "  - Max diameter = 94 km (some stores exceed 60 km radius from optimal center)\n",
    "  - Hard constraint forces split into 2 overlapping clusters\n",
    "  - F_r = 0.106 ‚Üí **cluster-aware method** (data-driven decision)\n",
    "  \n",
    "- **REP_002 (Guadalajara + Cuenca, 150 km apart)**: Produces **2 clusters**\n",
    "  - Natural separation between cities\n",
    "  - F_r = 0.282 ‚Üí **cluster-aware method** (data-driven decision)\n",
    "\n",
    "**Key Insight: Constraint-Based Clustering Behavior**\n",
    "- Center-radius constraint with D=60 km enforces **hard guarantees**\n",
    "- Even \"compact\" territories may require multiple clusters if max diameter exceeds 2√óD\n",
    "- This is **correct behavior** - ensures operational feasibility for daily routes\n",
    "- Method selection should be **data-driven** (based on F_r), not assumption-driven\n",
    "\n",
    "**Why Data-Driven Method Selection Matters:**\n",
    "- ‚ùå Hardcoded assumptions fail when clustering produces unexpected results\n",
    "- ‚úÖ Fragmentation score (F_r) correctly identifies multi-cluster territories\n",
    "- ‚úÖ Automatic fallback to cluster-aware method when F_r ‚â• 0.1\n",
    "- ‚úÖ Validates speed differential before applying dual-speed matrix\n",
    "\n",
    "**Why D Must Be Set by Business Rules:**\n",
    "- ‚ùå Data-driven D selection (median √ó factor) fails:\n",
    "  - Compact territories ‚Üí D too small ‚Üí over-clustering\n",
    "  - Fragmented territories ‚Üí D too large ‚Üí mega-clusters\n",
    "- ‚úÖ Business rule D=60 km based on:\n",
    "  - 8-hour work day constraint\n",
    "  - Typical daily driving capability (~200 km)\n",
    "  - Sales rep coverage standards\n",
    "\n",
    "### Constraint-Based vs DBSCAN\n",
    "\n",
    "**Advantages of Constraint-Based Clustering (with business rules):**\n",
    "- ‚úì **Hard guarantees** on cluster sizes (operationally enforceable)\n",
    "- ‚úì **Predictable** routing constraints for optimization algorithms\n",
    "- ‚úì **Business-aligned** (D reflects real operational limits)\n",
    "- ‚úì **Compliance-ready** (can enforce regulatory constraints)\n",
    "\n",
    "**Advantages of DBSCAN:**\n",
    "- ‚úì **Automatic** cluster detection (no D parameter needed)\n",
    "- ‚úì **Adapts to territory structure** (density-based, not distance-based)\n",
    "- ‚úì **Flexible shapes** (not limited to circular constraints)\n",
    "- ‚úì **Better for exploration** when business rules unknown\n",
    "\n",
    "**Recommendation for Route Planning:**\n",
    "- Use **Center-Radius (D=60 km)** when:\n",
    "  - Business rules exist (daily coverage limits, work hour constraints)\n",
    "  - Need guaranteed maximum cluster radius\n",
    "  - Want predictable TSP/VRP inputs\n",
    "  \n",
    "- Use **Diameter (D=60 km)** when:\n",
    "  - Need stricter guarantees (all pairwise distances ‚â§ D)\n",
    "  - Regulatory requirements on maximum travel between any two stores\n",
    "  \n",
    "- Use **DBSCAN** when:\n",
    "  - No clear business rules for D\n",
    "  - Territory structure unknown\n",
    "  - Prefer data-driven territory discovery\n",
    "  - Want to identify natural geographic groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "997d4007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL SUMMARY - Business Rule Clustering (D=60 km)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rep_id</th>\n",
       "      <th>clustering_method</th>\n",
       "      <th>time_matrix_method</th>\n",
       "      <th>fragmentation_score</th>\n",
       "      <th>territory_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REP_001</td>\n",
       "      <td>center_radius</td>\n",
       "      <td>cluster_aware</td>\n",
       "      <td>0.106090</td>\n",
       "      <td>Fragmented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REP_002</td>\n",
       "      <td>center_radius</td>\n",
       "      <td>cluster_aware</td>\n",
       "      <td>0.282306</td>\n",
       "      <td>Fragmented</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rep_id clustering_method time_matrix_method  fragmentation_score  \\\n",
       "0  REP_001     center_radius      cluster_aware             0.106090   \n",
       "1  REP_002     center_radius      cluster_aware             0.282306   \n",
       "\n",
       "  territory_status  \n",
       "0       Fragmented  \n",
       "1       Fragmented  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ Analysis complete!\n",
      "\n",
      "üìè Business Rules Applied:\n",
      "  ‚Ä¢ Maximum cluster radius: 60 km\n",
      "  ‚Ä¢ Work day constraint: 8 hours max (4 hours field work)\n",
      "  ‚Ä¢ Road factor: 1.4√ó (accounts for actual road distances)\n",
      "\n",
      "üìä Constraint-based clustering with business rules provides:\n",
      "  ‚Ä¢ Guaranteed maximum cluster sizes (operationally enforceable)\n",
      "  ‚Ä¢ Predictable route planning constraints\n",
      "  ‚Ä¢ Compliance with work hour regulations\n",
      "  ‚Ä¢ Alignment with real-world coverage capabilities\n",
      "\n",
      "‚úÖ Time matrices ready for TSP/VRP optimization\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY - Business Rule Clustering (D=60 km)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "for rep_id in ['REP_001', 'REP_002']:\n",
    "    r = results[rep_id]\n",
    "    summary_data.append({\n",
    "        'rep_id': rep_id,\n",
    "        'clustering_method': r['clustering_method'],\n",
    "        'time_matrix_method': r['method'],\n",
    "        'fragmentation_score': r['fragmentation_score'],\n",
    "        'territory_status': 'Compact' if r['fragmentation_score'] < 0.1 else 'Fragmented'\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "display(summary_df)\n",
    "\n",
    "print(\"\\nüéâ Analysis complete!\")\n",
    "print(\"\\nüìè Business Rules Applied:\")\n",
    "print(\"  ‚Ä¢ Maximum cluster radius: 60 km\")\n",
    "print(\"  ‚Ä¢ Work day constraint: 8 hours max (4 hours field work)\")\n",
    "print(\"  ‚Ä¢ Road factor: 1.4√ó (accounts for actual road distances)\")\n",
    "print(\"\\nüìä Constraint-based clustering with business rules provides:\")\n",
    "print(\"  ‚Ä¢ Guaranteed maximum cluster sizes (operationally enforceable)\")\n",
    "print(\"  ‚Ä¢ Predictable route planning constraints\")\n",
    "print(\"  ‚Ä¢ Compliance with work hour regulations\")\n",
    "print(\"  ‚Ä¢ Alignment with real-world coverage capabilities\")\n",
    "print(\"\\n‚úÖ Time matrices ready for TSP/VRP optimization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
